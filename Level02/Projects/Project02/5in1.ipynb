{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating System related operations\n",
    "import os\n",
    "\n",
    "# Image processing libraries\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "\n",
    "# Numerical operations and array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning related libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from vit_keras import vit\n",
    "import tensorflow as tf\n",
    "\n",
    "# Evaluation and metrics libraries\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreprocessor:\n",
    "    def __init__(self, target_size=(224, 224)):\n",
    "        self.target_size = target_size\n",
    "\n",
    "    # Updated function name for clarity and added normalization\n",
    "    def resize_and_normalize_image(self, image):\n",
    "        image = cv2.resize(image, self.target_size)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        return image\n",
    "\n",
    "    # Renamed function for consistency with the new preprocessing function name\n",
    "    def preprocess_image(self, image):\n",
    "        return self.resize_and_normalize_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_sample_images(directory, num_samples=5):\n",
    "#     classes = os.listdir(directory)\n",
    "#     for cls in classes:\n",
    "#         class_dir = os.path.join(directory, cls)\n",
    "#         image_files = os.listdir(class_dir)\n",
    "#         sample_files = random.sample(image_files, num_samples)\n",
    "        \n",
    "#         fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 2, 2))\n",
    "#         fig.suptitle(cls)\n",
    "#         for ax, file in zip(axes, sample_files):\n",
    "#             img_path = os.path.join(class_dir, file)\n",
    "#             img = Image.open(img_path)\n",
    "#             ax.imshow(img)\n",
    "#             ax.axis('off')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_class_distribution(directory):\n",
    "#     \"\"\"Plot the distribution of classes in the dataset.\"\"\"\n",
    "#     classes = os.listdir(directory)\n",
    "#     class_counts = {cls: len(os.listdir(os.path.join(directory, cls))) for cls in classes}\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.bar(class_counts.keys(), class_counts.values())\n",
    "#     plt.xlabel('Class')\n",
    "#     plt.ylabel('Number of images')\n",
    "#     plt.title('Class Distribution')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayClassifier:\n",
    "    def __init__(self, data_directory, csv_file, target_size=(224, 224), batch_size=32, preprocessor=None):\n",
    "        self.data_directory = data_directory\n",
    "        self.csv_file = csv_file\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessor = preprocessor or ImagePreprocessor(target_size=target_size)\n",
    "        self.model = None  # Model will be selected based on user choice\n",
    "        self.datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.2,\n",
    "            preprocessing_function=self.preprocessor.preprocess_image\n",
    "        )\n",
    "    \n",
    "    def display_sample_images(self, num_samples=5):\n",
    "        for cls in os.listdir(self.data_directory):\n",
    "            class_dir = os.path.join(self.data_directory, cls)\n",
    "            image_files = os.listdir(class_dir)\n",
    "\n",
    "            # Check if the number of samples requested is valid\n",
    "            if not (0 < num_samples <= len(image_files)):\n",
    "                print(f\"Warning: Insufficient images in '{class_dir}' to display {num_samples} samples.\")\n",
    "                continue  # Skip this class if insufficient samples\n",
    "\n",
    "            sample_files = random.sample(image_files, num_samples)\n",
    "            \n",
    "            fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 2, 2))\n",
    "            fig.suptitle(cls)\n",
    "            for ax, file in zip(axes, sample_files):\n",
    "                img_path = os.path.join(class_dir, file)\n",
    "                img = Image.open(img_path)\n",
    "                ax.imshow(img)\n",
    "                ax.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    def plot_class_distribution(self):\n",
    "        classes = os.listdir(self.data_directory)\n",
    "        class_counts = {cls: len(os.listdir(os.path.join(self.data_directory, cls))) for cls in classes}\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(class_counts.keys(), class_counts.values())\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Number of images')\n",
    "        plt.title('Class Distribution')\n",
    "        plt.show()    \n",
    "    \n",
    "    def build_vit_model(self):\n",
    "        vit_model = vit.vit_b16(\n",
    "            image_size=self.target_size,\n",
    "            activation='softmax',\n",
    "            pretrained=True,\n",
    "            include_top=False,\n",
    "            pretrained_top=False,\n",
    "            classes=3\n",
    "        )\n",
    "        model = Sequential([\n",
    "            vit_model,\n",
    "            Flatten(),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def build_efficientnet_model(self):\n",
    "        base_model = EfficientNetB0(include_top=False, input_shape=(*self.target_size, 3), weights=\"imagenet\")\n",
    "        base_model.trainable = False  # Freeze the base_model\n",
    "        model = Sequential([\n",
    "            base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def compile_and_train(self, model_choice='vit'):\n",
    "        self.display_sample_images()\n",
    "        self.plot_class_distribution()\n",
    "        if model_choice == 'vit':\n",
    "            self.model = self.build_vit_model()\n",
    "        elif model_choice == 'efficientnet':\n",
    "            self.model = self.build_efficientnet_model()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model choice. Please choose 'vit' or 'efficientnet'.\")\n",
    "\n",
    "        self.model.compile(optimizer=Adam(),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "        train_generator = self.datagen.flow_from_directory(\n",
    "            os.path.join(self.data_directory, 'train'),  # if 'train' is a subdirectory inside `self.data_directory`\n",
    "            target_size=self.target_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training'\n",
    "        )\n",
    "\n",
    "        validation_generator = self.datagen.flow_from_directory(\n",
    "            os.path.join(self.data_directory, 'train'),  # same here\n",
    "            target_size=self.target_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation'\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        history = self.model.fit(\n",
    "            train_generator,\n",
    "            epochs=30,\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def plot_history(self, history, model_name):\n",
    "        \n",
    "        # Plotting accuracy\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title(f'{model_name} Training and Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plotting loss\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f'{model_name} Training and Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def evaluate_model(self, test_directory):\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "            test_directory,\n",
    "            target_size=self.target_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        predictions = self.model.predict(test_generator)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "        true_labels = test_generator.classes\n",
    "        cm = confusion_matrix(true_labels, predicted_labels)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=test_generator.class_indices.keys(),\n",
    "                    yticklabels=test_generator.class_indices.keys())\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels, target_names=list(test_generator.class_indices.keys())))\n",
    "    \n",
    "    def save_model(self, file_path):\n",
    "        \n",
    "        self.model.save(file_path)\n",
    "        print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_directory = 'Data'\n",
    "# csv_file = 'train.csv'  \n",
    "# train_directory = os.path.join(data_directory, 'train')\n",
    "# test_directory = os.path.join(data_directory, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_sample_images(train_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visual displays a sample of chest X-ray images used for training a machine learning model to detect pneumonia, including cases of COVID-19. The dataset appears to be divided into three categories:\n",
    "\n",
    "1. `normal` - These images represent a set of normal chest X-rays where no pneumonia is present. They serve as the control group in the dataset. The images have a consistent clarity where lung fields, the heart, and the diaphragm boundaries can be clearly seen.\n",
    "\n",
    "2. `covid` - This category includes X-rays of patients who have been diagnosed with COVID-19. The images typically show signs of pneumonia, such as hazy opacities in the lung fields, which are indicative of viral infections like COVID-19.\n",
    "\n",
    "3. `virus` - These X-rays represent cases of vius not necessarily caused by the COVID-19 virus. Features may include diffuse lung involvement and other patterns that differentiate it from the normal and COVID-19 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_class_distribution(train_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart illustrates the distribution of different classes of chest X-ray images in a training dataset. This distribution is critical for understanding the dataset's composition and potential biases that could affect a machine learning model's training process.\n",
    "\n",
    "- `normal`: Represents a large number of images showing no signs of pneumonia. This class has the highest count, indicating a substantial set of examples for the model to learn what a healthy chest X-ray looks like.\n",
    "\n",
    "- `covid`: Contains a fewer number of images compared to the `normal` class. These images are of patients diagnosed with COVID-19 and display characteristics of viral pneumonia in chest X-rays.\n",
    "\n",
    "- `virus`: Slightly fewer images than the `normal` class but more than the `covid` class. This group includes images of viral pneumonia not attributed to COVID-19.\n",
    "\n",
    "The disparity in the number of images across classes can lead to class imbalance issues, where a model might become biased towards the class with more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = ChestXRayClassifier(data_directory, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_vit = classifier.compile_and_train(model_choice='vit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.plot_history(history_vit, model_name='Vision Transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_efficientnet = classifier.compile_and_train(model_choice='efficientnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.plot_history(history_efficientnet, model_name='EfficientNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.evaluate_model(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.save_model('Models/h5/main.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "\n",
    "# # Specify the path to save the Keras model\n",
    "# keras_model_path = 'Models/h5/'\n",
    "# classifier.save_model(keras_model_path)\n",
    "\n",
    "# # Convert the model to TFLite format\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(classifier.model)\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the TFLite model to a binary file\n",
    "# tflite_model_path = 'Models/tf/main.tflite'\n",
    "# with open(tflite_model_path, 'wb') as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model(\"Models/h5/\")\n",
    "\n",
    "# image_preprocessor = ImagePreprocessor(target_size=(224, 224))\n",
    "\n",
    "# submission_df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = test_datagen.flow_from_dataframe(\n",
    "#     dataframe=submission_df,\n",
    "#     directory='Data/test',\n",
    "#     x_col='Image',\n",
    "#     y_col=None,\n",
    "#     class_mode=None,\n",
    "#     target_size=(224, 224),\n",
    "#     shuffle=False,\n",
    "#     batch_size=32\n",
    "# )\n",
    "\n",
    "# predictions = model.predict(test_generator, steps=len(test_generator))\n",
    "\n",
    "# predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# submission_df['Label'] = predicted_labels\n",
    "\n",
    "# submission_df.to_csv('Sub/kaggle_submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
